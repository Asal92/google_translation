'''
11/11/2022

Renamed some variables to make them more clear.
Looks like it's not actually adding sentences because it's expecting there to be a space rather than these underlines so I'm confused.

I don't know what the preprocess function is for.

When I try to run the code, it doesn't seem to work because no sentences are added.

I'm going to actually switch to use Ku's branch rather than this one.

Unsure if I should rebase or how to do this best.
I'm worried that a merge will keep some changes from Asal or me that I don't want.
If I create a new branch, I have to rename this one.

That should actually be fine.
That's what I'll do, then.

Great, on the new branch now!

It's looking likely that neither Ku nor Asal followed the paper.
The paper doesn't linearize the tags while doing the Google Translate conversion.
Should I follow what my group has already done and call it a new technique?
Or should I stick to the paper and do it the right way?

Let's cut down the number of sentences we translate and see how long it takes / what the format of the output is like.

Ooh we actually already have examples of the output. Great!

Let's do it for French and see what happens! I think the postprocessing code will be broken but that's okay.
'''

'''
11/12/2022

Here's what I posted in the chat last night:
    Finally got a handle on the code today. Should have the datasets we need (with translation of entities and without translation of entities) by tomorrow's meeting as promised.
    One thing that I found in the code is that we weren't following the MulDA method described in the paper. So, I'm going to rewrite it so it works the way MulDA does so that we're closer to the original. The main thing is that MulDA never linearizes the tags while doing the translation. As described in the document, MulDA has three steps - 1: translate with the entity tags (not linearization) 2: translate with the original term in brackets (not linearization) 3: replace the entity tags with the translated term (in our case, replace the entity tags with the non-translated term). The linearization (DAGA stuff) doesn't come into MulDA until the generation step, which we're not doing.
    Another thing is that we seem to be replacing unicode symbols by hand, which shouldn't be needed at all. As long as the data is read into our AI model using UTF-8 encoding, those \u and & values should remain in the .txt files. See these questions (1, 2, and 3) for more information.


So, what I need to do is essentially recode this from scratch.
The Google format is pretty easy to deal with, as is the MulDA stuff, so I'm not too worried.
Let's do it!

At some point we'll need a dictionary where an index points to the example number and the index of the word that's being translated in the sentence.

I think Ku was also missing some labels.

This sentence makes the bracket idea not work:
    siegfried ( ca . 1906 ) photo by aimé dupont ]]

And there's another sentence that has braces:
    inome _ _ O
    fishing _ _ O
    port _ _ O
    izumo _ _ B-HumanSettlement
    shimane _ _ B-ORG
    prefecture _ _ I-ORG
    japan _ _ B-HumanSettlement
    { _ _ O
    nwp _ _ O
    } _ _ O

So I think using quotes will be the best idea.

In order to get this to work in time, I'll be ignoring sentences without any entities.

We're going to be doing it slightly different than MulDA in that we're not going to be substituting the token in. We're just going to surround it in quotes.

I think ours should work better anyways.
Would be a good thing to test later.

I'm untranslating each entity individually.
Can write more code later to untranslate them all together.

Looks like something is off with the tabs

It also looks like something is wrong with the translated one (not the orig one)

This example is tricky:
    {
    "translatedText": "en collaboration avec \"robert gompf\", il a d\u00e9couvert des mod\u00e8les quadridimensionnels de la topologie de l'espace-temps.",
    "input": "jointly with \"robert gompf\" he discovered four dimensional models of space time topology ."
    },

It looks like in most examples the comma is its own token, unless it's in a number.

So I think we need to separate things off of quotes if it happens.

I've currently turned the quotes into backticks.

I think we will need to merge them all together, otherwise the AI will train incorrectly.

Okay, I may have made a huge mistake.

If it's translating each of the bracketed words separately, how do we know the default to put them in?
We can't put the translated ones back into the original one, because the original one isn't translated.
We also don't know where the non-bracketed ones went.

Actually, what if we take out the brackets? Shouldn't all of them be the same?
Yes. If they're not, we should ignore that example. That makes sense!

I think for the time being I'm going to skip the complicated cases with the symbols attached to the brackets.

Quotes in French are converted into "«»" also known as Guillemets, so I don't think we want to use quotes as the brackets.

I'm going to see if the same thing happens to backticks.

If so, then I'll just skip examples where that happens.

This site is super helpful for seeing what characters are in text:
    https://www.soscisurvey.de/tools/view-chars.php

Everything says its a tab, so I'm just going to go with it.

With quotes we end up skipping a lot:
    Skipped 8559/16778 sentences

Let's try backticks!

Even worse:
    Skipped 12808/16778 sentences
    Skipped 0 sentences due to invalid bracketing (usually from the original sentence containing the bracket characters)
    Skipped 10975 sentences due to brackets not being found
    Skipped 1198 sentences due to translations not matching
    Skipped 635 sentences due to template token mismatch (usually from punctuation added after an entity)

Looks like it converts backticks into quotes at times too.

What if we actually use brackets?

It fails - I'm going to make it so it doesn't.

With square bracketing:
    Skipped 5858/16778 sentences
    Skipped 72 sentences due to invalid bracketing (usually from the original sentence containing the bracket characters)
    Skipped 54 sentences due to brackets not being found
    Skipped 4153 sentences due to translations not matching
    Skipped 1579 sentences due to template token mismatch (usually from punctuation added after an entity)

With curly braces:
    Skipped 5780/16778 sentences
    Skipped 1 sentences due to invalid bracketing (usually from the original sentence containing the bracket characters)
    Skipped 49 sentences due to brackets not being found
    Skipped 4087 sentences due to translations not matching
    Skipped 1643 sentences due to template token mismatch (usually from punctuation added after an entity)

It seems like a lot of the curly braces ones are because it's literally not translating the word in all cases.

With angular brackets:
    Skipped 5599/16778 sentences
    Skipped 5 sentences due to invalid bracketing (usually from the original sentence containing the bracket characters)
    Skipped 98 sentences due to brackets not being found
    Skipped 4039 sentences due to translations not matching
    Skipped 1457 sentences due to template token mismatch (usually from punctuation added after an entity)

With parentheses:
    Skipped 7440/16778 sentences
    Skipped 2459 sentences due to invalid bracketing (usually from the original sentence containing the bracket characters)        
    Skipped 108 sentences due to brackets not being found
    Skipped 3526 sentences due to translations not matching
    Skipped 1347 sentences due to template token mismatch (usually from punctuation added after an entity)



TEMPLATE TOKEN MISMATCH ISSUE FIXED


Quotes (with template token mismatch issue fixed):
    Skipped 5304/16778 sentences
    Skipped 0 sentences due to invalid bracketing (usually from the original sentence containing the bracket characters)
    Skipped 1823 sentences due to brackets not being found
    Skipped 3481 sentences due to translations not matching
    Skipped 0 sentences due to template token mismatch (usually from punctuation added after an entity)

I'm going to try quotes again now that I've fixed this.
'''